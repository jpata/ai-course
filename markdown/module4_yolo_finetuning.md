---
jupyter:
  jupytext:
    default_lexer: python
    text_representation:
      extension: .md
      format_name: markdown
      format_version: '1.3'
      jupytext_version: 1.18.1
  kernelspec:
    display_name: Python 3 (ipykernel)
    language: python
    name: python3
---

<!-- #region -->
# YOLO Fine-Tuning

This notebook demonstrates how to fine-tune a YOLO model on a custom dataset. The dataset was labeled automatically using the OWL2 model in the `module4_owl2_object_detection.md` notebook.

First, let's install the necessary libraries.

```python
#!pip install -q ultralytics pandas pyyaml scikit-learn
```

Now, let's import the required libraries.
<!-- #endregion -->

```python
import os
import yaml
from ultralytics import YOLO
from PIL import Image
from IPython.display import display
import pandas as pd

import matplotlib
%matplotlib inline
import matplotlib.pyplot as plt
```

<!-- #region -->
## Create Dataset YAML

YOLO models require a `dataset.yaml` file that specifies the dataset paths and class names. We will create this file now. The labels were generated by the OWL2 notebook and are located in `data/IDLE-OO-Camera-Traps/labels/test`. The corresponding images are in `data/IDLE-OO-Camera-Traps/data/test`.

**Note:** The `module4_owl2_object_detection.md` notebook only generates labels for a small sample of 10 images. Fine-tuning on such a small dataset will not produce a robust model, but it demonstrates the process. For better results, you should generate labels for a larger portion of the dataset.
<!-- #endregion -->

```python
import glob
from sklearn.model_selection import train_test_split

# --- Find all labeled images and create train.txt and val.txt ---
base_path = '/home/joosep/ai-course/data/IDLE-OO-Camera-Traps_yolo'
labels_dir = os.path.join(base_path, 'labels')
images_dir = os.path.join(base_path, 'images')
train_file_path = os.path.join(base_path, 'train.txt')
val_file_path = os.path.join(base_path, 'val.txt')
image_files = []

# Recursively find all .txt files in the labels directory, excluding classes.txt
label_files = [f for f in glob.glob(os.path.join(labels_dir, '**/*.txt'), recursive=True) if os.path.basename(f) != 'classes.txt']

for label_file in label_files:
    # Derive the corresponding image path, assuming .png extension
    relative_label_path = os.path.relpath(label_file, labels_dir)
    image_name = os.path.splitext(relative_label_path)[0] + '.png'
    image_path = os.path.join(images_dir, image_name)
    
    if os.path.exists(image_path):
        image_files.append(image_path)

if not image_files:
    raise Exception("No labeled images found. 'train.txt' and 'val.txt' were not created.")

# Split the data into training and validation sets (80% train, 20% val)
train_images, val_images = train_test_split(image_files, test_size=0.2, random_state=42)

# Write the absolute paths of labeled images to train.txt
with open(train_file_path, 'w') as f:
    for image_path in train_images:
        f.write(f"{image_path}\n")
print(f"Found {len(image_files)} labeled images.")
print(f"Created '{train_file_path}' with {len(train_images)} images for training.")

# Write the absolute paths of labeled images to val.txt
with open(val_file_path, 'w') as f:
    for image_path in val_images:
        f.write(f"{image_path}\n")
print(f"Created '{val_file_path}' with {len(val_images)} images for validation.")


# --- Create dataset.yaml ---
dataset_config = {
    'path': base_path,
    'train': train_file_path,  # Path to the file with image paths
    'val': val_file_path,    # Path to the file with validation image paths
    'names': {}
}
classes_path = os.path.join(os.path.dirname(labels_dir), 'classes.txt')

try:
    with open(classes_path, 'r') as f:
        classes = [line.strip() for line in f.readlines()]
        dataset_config['names'] = {i: name for i, name in enumerate(classes)}

    with open('ena24_yolo_dataset.yaml', 'w') as f:
        yaml.dump(dataset_config, f)

    print("\nena24_yolo_dataset.yaml created:")
    with open('ena24_yolo_dataset.yaml', 'r') as f:
        print(f.read())
except FileNotFoundError:
    print(f"\nError: '{classes_path}' not found.")
    raise Exception("Please run the 'Automatic data labelling' section of the 'module4_owl2_object_detection.md' notebook to generate labels and the classes.txt file.")

```

<!-- #region -->
## Fine-Tune YOLO Model

Now we can load a pretrained YOLO model and fine-tune it on our custom dataset. We'll use the `yolov8n.pt` model.

If the `ena24_yolo_dataset.yaml` was created successfully, we can proceed with training.
<!-- #endregion -->

```python
# Load a pretrained YOLO model
model = YOLO('yolov8n.pt')

# Train the model
results = model.train(data='ena24_yolo_dataset.yaml', epochs=100, imgsz=640, batch=4)
```

<!-- #region -->
## View Results

After training, the best model is saved in the `runs/detect/train/weights/` directory. Let's load this model and run inference on one of the images used for training to verify that the model has learned.

We will select one of the 10 sample images that were labeled.

<!-- #endregion -->

```python
# Path to the directory where training runs are saved
train_dir = 'runs/detect'

# Find the latest training directory
latest_train_run = max(os.listdir(train_dir), key=lambda d: os.path.getmtime(os.path.join(train_dir, d)))
best_model_path = os.path.join(train_dir, latest_train_run, 'weights/best.pt')

print(f"Loading fine-tuned model from: {best_model_path}")

# Load the fine-tuned model
model_finetuned = YOLO(best_model_path)

# Get the paths of up to 9 validation images
if len(val_images) < 9:
    print(f"Warning: Found only {len(val_images)} validation images. Displaying all of them.")
    display_images = val_images
else:
    display_images = val_images[:9]

if not display_images:
    raise Exception("No validation images found to display results.")

# Create a 3x3 grid for displaying the images
fig, axs = plt.subplots(3, 3, figsize=(15, 15))
axs = axs.flatten()

# Run inference and display results
for i, image_path in enumerate(display_images):
    print(f"Running inference on: {image_path}")
    results = model_finetuned(image_path)
    
    # Plot results and convert to an image
    im_array = results[0].plot()
    im = Image.fromarray(im_array[..., ::-1])
    
    # Display the image in the subplot
    axs[i].imshow(im)
    axs[i].axis('off') # Hide axes
    axs[i].set_title(os.path.basename(image_path))

# Hide any unused subplots
for j in range(i + 1, len(axs)):
    axs[j].axis('off')

plt.tight_layout()
plt.show()
```

<!-- #region -->
## YOLO Network Architecture Analysis

To understand how the YOLO model turns image features into predictions, we can inspect its architecture. The model is generally composed of three main parts: the **Backbone**, the **Neck**, and the **Head**.

*   **Backbone**: This is a deep convolutional neural network that extracts features from the input image at various scales. YOLOv8 uses a modified CSPDarknet53 architecture.
*   **Neck**: This part connects the backbone to the head. It takes feature maps from different stages of the backbone and combines them to create richer feature pyramids. This allows the model to detect objects of different sizes more effectively. YOLOv8 uses a Path Aggregation Network (PANet) for this.
*   **Head (Detection)**: This is the final part of the network that generates the output predictions. It takes the feature maps from the neck and produces bounding boxes, class probabilities, and objectness scores.

Let's print the model structure to see the layers. We will use the pretrained `yolov8n.pt` model for this analysis.
<!-- #endregion -->

```python
# Load a pretrained YOLO model to inspect its architecture
model_to_inspect = YOLO('yolov8n.pt')
print(model_to_inspect.model)
```

<!-- #region -->
### From Features to Predictions

The key to understanding the prediction process lies in the `Detect` module at the end of the network structure (the last layer in the printed output).

1.  **Input Feature Maps**: The `Detect` head receives feature maps from the neck at three different scales (e.g., 80x80, 40x40, 20x20 for a 640x640 input). Each scale is responsible for detecting objects of a corresponding size (small, medium, large).

2.  **Convolutional Prediction**: For each feature map, the `Detect` head applies a set of 1x1 convolutional layers. These convolutions transform the feature map's channels into a format that represents the predictions. For each location (or "patch") in the feature map, the model predicts:
    *   **Bounding Box Coordinates (4 values)**: These are typically `(x_center, y_center, width, height)`, which are regressed relative to the grid cell's location.
    *   **Class Probabilities (C values)**: A probability for each of the `C` classes the model was trained on.
    *   **Objectness Score (1 value)**: This is often implicitly part of the class prediction or a separate score indicating the confidence that an object is present in the bounding box. In YOLOv8, the box and class predictions are decoupled.

3.  **Output Tensor**: The output of the `Detect` head is a set of tensors. For a single image, the predictions from all scales are concatenated. The final output tensor has a shape like `(batch_size, num_classes + 4, num_predictions)`, where `num_predictions` is the total number of prediction anchors across all scales.

4.  **Decoding the Output**: This raw tensor output is then post-processed:
    *   The bounding box values are scaled to the original image dimensions.
    *   The class scores are passed through a softmax or sigmoid function to get final probabilities.
    *   Non-Maximum Suppression (NMS) is applied to filter out overlapping bounding boxes for the same object, keeping only the one with the highest confidence score.

This process allows the model to efficiently predict multiple objects of various sizes and classes in a single forward pass.
<!-- #endregion -->

<!-- #region -->
## Visualize Training and Validation Loss
<!-- #endregion -->

```python
# Find the latest training directory
results_csv_path = os.path.join(train_dir, latest_train_run, 'results.csv')

print(f"Loading training results from: {results_csv_path}")
results_df = pd.read_csv(results_csv_path)

fig = plt.figure(figsize=(12, 6))
plt.plot(results_df['epoch'], results_df['train/box_loss']+results_df['train/cls_loss']+results_df['train/dfl_loss'], label='Train Loss')
plt.plot(results_df['epoch'], results_df['val/box_loss']+results_df['val/cls_loss']+results_df['val/dfl_loss'], label='Val Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training and Validation Loss Curves')
plt.legend()
```