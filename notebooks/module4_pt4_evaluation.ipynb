{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fee90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mount the drive in colab to be able to share outputs across the notebooks\n",
    "import sys\n",
    "import os\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive/')\n",
    "\n",
    "    %mkdir -p /content/drive/MyDrive/ai-course\n",
    "    %cd /content/drive/MyDrive/ai-course\n",
    "\n",
    "    if not os.path.exists('ai-course'):\n",
    "        !git clone https://github.com/jpata/ai-course\n",
    "    \n",
    "    %cd ai-course\n",
    "    !git pull"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d65f472",
   "metadata": {},
   "source": [
    "# YOLO Fine-Tuned Model Evaluation\n",
    "\n",
    "This notebook evaluates a fine-tuned YOLO model. It assumes that you have already run the `module4_yolo_finetuning.md` notebook to train the model.\n",
    "\n",
    "This notebook will:\n",
    "1. Load the best model from the latest training run.\n",
    "2. Display predictions on a sample of validation images.\n",
    "3. Visualize the training and validation loss curves.\n",
    "4. Evaluate the model on the entire validation set and display the confusion matrix.\n",
    "\n",
    "First, let's import the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13473b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tqdm\n",
    "\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3d4cd9",
   "metadata": {},
   "source": [
    "## Setup Paths\n",
    "\n",
    "We need to define the paths to the dataset and validation files. This should be consistent with the `module4_yolo_finetuning.md` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980eb678",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = os.path.abspath('../data/IDLE-OO-Camera-Traps_yolo')\n",
    "val_file_path = os.path.join(base_path, 'val.txt')\n",
    "\n",
    "with open(val_file_path, 'r') as f:\n",
    "    val_images = [line.strip() for line in f.readlines()]\n",
    "print(f\"Found {len(val_images)} validation images.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bb419c",
   "metadata": {},
   "source": [
    "## View Results\n",
    "\n",
    "After training, the best model is saved in the `runs/detect/train/weights/` directory. Let's load this model and run inference on one of the images used for training to verify that the model has learned.\n",
    "\n",
    "We will select one of the 10 sample images that were labeled.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c06862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the directory where all YOLO training runs are saved\n",
    "train_dir = 'runs/detect'\n",
    "\n",
    "# Find the most recent training directory by sorting them by modification time\n",
    "latest_train_run = max(os.listdir(train_dir), key=lambda d: os.path.getmtime(os.path.join(train_dir, d)))\n",
    "# The best model weights are saved as 'best.pt' inside the 'weights' subdirectory\n",
    "best_model_path = os.path.join(train_dir, latest_train_run, 'weights/best.pt')\n",
    "\n",
    "print(f\"Loading fine-tuned model from: {best_model_path}\")\n",
    "\n",
    "# Load the fine-tuned model from the best weights file\n",
    "model_finetuned = YOLO(best_model_path)\n",
    "\n",
    "# Get the paths of up to 9 validation images to display\n",
    "if len(val_images) < 9:\n",
    "    print(f\"Warning: Found only {len(val_images)} validation images. Displaying all of them.\")\n",
    "    display_images = val_images\n",
    "else:\n",
    "    # Select the first 9 images from the validation set\n",
    "    display_images = val_images[:9]\n",
    "\n",
    "if not display_images:\n",
    "    raise Exception(\"No validation images found to display results.\")\n",
    "\n",
    "# Create a 3x3 grid for displaying the images and their predictions\n",
    "fig, axs = plt.subplots(3, 3, figsize=(15, 15))\n",
    "axs = axs.flatten() # Flatten the 2D array of axes into a 1D array for easy iteration\n",
    "\n",
    "# Run inference on the selected images and display the results\n",
    "for i, image_path in enumerate(display_images):\n",
    "    # Note: YOLO expects the original image path, not the pre-processed one\n",
    "    print(f\"Running inference on: {image_path}\")\n",
    "    # Run the fine-tuned model on the image\n",
    "    results = model_finetuned(image_path)\n",
    "    \n",
    "    # The `plot()` method returns a numpy array of the image with bounding boxes and labels drawn on it\n",
    "    im_array = results[0].plot()\n",
    "    # Convert the array from BGR (used by OpenCV) to RGB for correct display with PIL and Matplotlib\n",
    "    im = Image.fromarray(im_array[..., ::-1])\n",
    "    \n",
    "    # Display the image in the current subplot\n",
    "    axs[i].imshow(im)\n",
    "    axs[i].axis('off') # Hide the x and y axes\n",
    "    axs[i].set_title(os.path.basename(image_path))\n",
    "\n",
    "# Hide any unused subplots if there are fewer than 9 images\n",
    "for j in range(i + 1, len(axs)):\n",
    "    axs[j].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4591091",
   "metadata": {},
   "source": [
    "## Evaluate on Validation Set and Visualize Confusion Matrix\n",
    "\n",
    "Now that we have a fine-tuned model, let's evaluate its performance on the entire validation set. This will give us metrics like mAP (mean Average Precision) and also allow us to generate a confusion matrix to see how well the model distinguishes between different classes.\n",
    "\n",
    "The `val()` method will run prediction on all images in the validation set defined in `ena24_yolo_dataset.yaml`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a344101f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the directory where training runs are saved\n",
    "train_dir = 'runs/detect'\n",
    "\n",
    "# Find the latest training directory\n",
    "latest_train_run = max(os.listdir(train_dir), key=lambda d: os.path.getmtime(os.path.join(train_dir, d)))\n",
    "best_model_path = os.path.join(train_dir, latest_train_run, 'weights/best.pt')\n",
    "\n",
    "print(f\"Loading fine-tuned model from: {best_model_path}\")\n",
    "\n",
    "# Load the fine-tuned model\n",
    "model_finetuned = YOLO(best_model_path)\n",
    "\n",
    "# Run the `val` method to evaluate the model on the validation set.\n",
    "# This uses the 'val' dataset defined in the 'ena24_yolo_dataset.yaml' file.\n",
    "# The method calculates metrics like mAP, precision, and recall, and saves results to a new run directory.\n",
    "metrics = model_finetuned.val()\n",
    "\n",
    "# The validation process automatically generates and saves a confusion matrix image.\n",
    "# We can find its path in the `save_dir` attribute of the returned metrics object.\n",
    "confusion_matrix_path = os.path.join(metrics.save_dir, 'confusion_matrix.png')\n",
    "\n",
    "# Check if the confusion matrix image was created successfully\n",
    "if os.path.exists(confusion_matrix_path):\n",
    "    print(f\"Displaying confusion matrix from: {confusion_matrix_path}\")\n",
    "    # Open and display the confusion matrix image\n",
    "    img = Image.open(confusion_matrix_path)\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off') # Hide the axes for a cleaner look\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"Confusion matrix not found at: {confusion_matrix_path}\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "default_lexer": "python"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
