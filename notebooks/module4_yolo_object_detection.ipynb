{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e035e5b3",
   "metadata": {},
   "source": [
    "# Object Detection with YOLO\n",
    "\n",
    "This notebook demonstrates how to use the YOLO model for object detection on the IDLE-OO-Camera-Traps dataset.\n",
    "\n",
    "First, let's install the necessary libraries.\n",
    "\n",
    "```python\n",
    "!pip install -q transformers datasets torch torchvision Pillow ultralytics scikit-learn\n",
    "```\n",
    "\n",
    "Now, let's import the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a8f8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from PIL import Image\n",
    "from IPython.display import display,HTML\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc35d04",
   "metadata": {},
   "source": [
    "## YOLO Object Detection\n",
    "\n",
    "First, we'll use a pretrained YOLOv8 model to perform object detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057583b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pretrained YOLO model\n",
    "model_yolo = YOLO('yolov8n.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0a1e07",
   "metadata": {},
   "source": [
    "Next, we load the `imageomics/IDLE-OO-Camera-Traps` dataset. We'll just take one example from the training split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6773c2",
   "metadata": {
    "label": "load-image-cell"
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"imageomics/IDLE-OO-Camera-Traps\", split=\"test\", streaming=True)\n",
    "iterator = iter(dataset)\n",
    "sample = next(iterator)\n",
    "image = sample[\"image\"]\n",
    "display(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3527b9c",
   "metadata": {},
   "source": [
    "Now we can run the YOLO model on the image. We'll test three different confidence thresholds: 0.5, 0.1, and 0.001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ddfe62",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "confidence_thresholds = [0.5, 0.1, 0.001]\n",
    "\n",
    "for conf in confidence_thresholds:\n",
    "    print(f\"Running YOLO detection with confidence threshold: {conf}\")\n",
    "    # Run inference on a copy of the image\n",
    "    results_yolo = model_yolo(image.copy(), conf=conf)\n",
    "\n",
    "    # Plot results\n",
    "    im_array = results_yolo[0].plot()\n",
    "    im = Image.fromarray(im_array[..., ::-1])  # RGB PIL image\n",
    "    display(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678cbf3d",
   "metadata": {},
   "source": [
    "### YOLO Intermediate Layer Visualization\n",
    "\n",
    "Now, let's visualize the intermediate outputs of the YOLO model. We will add hooks to the model layers to capture the feature maps and then plot them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792012ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list to store the feature maps\n",
    "feature_maps = []\n",
    "hooks = []\n",
    "\n",
    "# The hook function that saves the output of a layer\n",
    "def hook_fn(module, input, output):\n",
    "    feature_maps.append(output)\n",
    "\n",
    "# We will visualize the output of the first 10 layers of the YOLO model\n",
    "detection_model = model_yolo.model\n",
    "layers_to_hook = detection_model.model[:10]\n",
    "\n",
    "# Register a forward hook for each layer to be visualized\n",
    "for layer in layers_to_hook:\n",
    "    hooks.append(layer.register_forward_hook(hook_fn))\n",
    "\n",
    "# Run inference to trigger the hooks.\n",
    "# Make sure to clear feature_maps before running, as hooks are global.\n",
    "feature_maps = []\n",
    "results_yolo = model_yolo(image.copy())\n",
    "\n",
    "# Remove the hooks after inference\n",
    "for hook in hooks:\n",
    "    hook.remove()\n",
    "\n",
    "# Now, let's visualize the feature maps\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "\n",
    "num_layers = len(feature_maps)\n",
    "layer_names = [f\"Layer {i}: {type(layers_to_hook[i]).__name__}\" for i in range(num_layers)]\n",
    "\n",
    "# Plot the feature maps in a grid\n",
    "cols = 4\n",
    "rows = (num_layers + cols - 1) // cols\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(15, 4 * rows))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, (fm, name) in enumerate(zip(feature_maps, layer_names)):\n",
    "    # Detach the tensor from the computation graph and move it to the CPU\n",
    "    fm = fm.detach().cpu()\n",
    "    # Get the feature map for the first image in the batch\n",
    "    fm = fm[0]\n",
    "    \n",
    "    C, H, W = fm.shape\n",
    "    \n",
    "    ax = axes[i]\n",
    "\n",
    "    # Use PCA to visualize the feature map's channel dimension\n",
    "    if C >= 3:\n",
    "        # Reshape for PCA: from (C, H, W) to (H*W, C)\n",
    "        data = fm.permute(1, 2, 0).reshape(H * W, C).numpy()\n",
    "        \n",
    "        # Apply PCA to reduce to 3 components for RGB visualization\n",
    "        pca = PCA(n_components=3)\n",
    "        pca_result = pca.fit_transform(data)\n",
    "        \n",
    "        # Reshape back to an image (H, W, 3)\n",
    "        pca_image = pca_result.reshape(H, W, 3)\n",
    "        \n",
    "        # Normalize each of the 3 principal components to the range [0, 1]\n",
    "        for c in range(3):\n",
    "            channel = pca_image[:, :, c]\n",
    "            min_val, max_val = channel.min(), channel.max()\n",
    "            if max_val > min_val:\n",
    "                pca_image[:, :, c] = (channel - min_val) / (max_val - min_val)\n",
    "            else:\n",
    "                pca_image[:, :, c] = 0\n",
    "        \n",
    "        ax.imshow(pca_image)\n",
    "        ax.set_title(name)\n",
    "    else:\n",
    "        # Fallback for layers with fewer than 3 channels: show the first channel in grayscale\n",
    "        ax.imshow(fm[0], cmap='gray')\n",
    "        ax.set_title(name + \" (grayscale)\")\n",
    "\n",
    "    ax.axis('off')\n",
    "\n",
    "# Hide any unused subplots\n",
    "for j in range(i + 1, len(axes)):\n",
    "    axes[j].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "default_lexer": "python"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
