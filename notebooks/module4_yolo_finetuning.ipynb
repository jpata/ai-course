{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb3eb7e4",
   "metadata": {},
   "source": [
    "# YOLO Fine-Tuning\n",
    "\n",
    "This notebook demonstrates how to fine-tune a YOLO model on a custom dataset. The dataset was labeled automatically using the OWL2 model in the `module4_owl2_object_detection.md` notebook.\n",
    "\n",
    "First, let's install the necessary libraries.\n",
    "\n",
    "```python\n",
    "#!pip install -q ultralytics pandas pyyaml scikit-learn\n",
    "```\n",
    "\n",
    "Now, let's import the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3ab713",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tqdm\n",
    "\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a27d2f",
   "metadata": {},
   "source": [
    "## Create Dataset YAML\n",
    "\n",
    "YOLO models require a `dataset.yaml` file that specifies the dataset paths and class names. We will create this file now. The labels were generated by the OWL2 notebook and are located in `data/IDLE-OO-Camera-Traps/labels/test`. The corresponding images are in `data/IDLE-OO-Camera-Traps/data/test`.\n",
    "\n",
    "**Note:** The `module4_owl2_object_detection.md` notebook only generates labels for a small sample of 10 images. Fine-tuning on such a small dataset will not produce a robust model, but it demonstrates the process. For better results, you should generate labels for a larger portion of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c6c783",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# --- Find all labeled images and create train.txt and val.txt ---\n",
    "base_path = os.path.abspath('../data/IDLE-OO-Camera-Traps_yolo')\n",
    "labels_dir = os.path.join(base_path, 'labels')\n",
    "images_dir = os.path.join(base_path, 'images')\n",
    "train_file_path = os.path.join(base_path, 'train.txt')\n",
    "val_file_path = os.path.join(base_path, 'val.txt')\n",
    "image_files = []\n",
    "\n",
    "# Recursively find all .txt files in the labels directory, excluding classes.txt\n",
    "label_files = [f for f in glob.glob(os.path.join(labels_dir, '**/*.txt'), recursive=True) if os.path.basename(f) != 'classes.txt']\n",
    "\n",
    "for label_file in label_files:\n",
    "    # Derive the corresponding image path, assuming .png extension\n",
    "    image_path = label_file.replace(\"/labels/\", \"/images/\").replace(\".txt\", \".png\")\n",
    "    if os.path.exists(image_path):\n",
    "        image_files.append(image_path)\n",
    "\n",
    "if not image_files:\n",
    "    raise Exception(\"No labeled images found. 'train.txt' and 'val.txt' were not created.\")\n",
    "\n",
    "# Split the data into training and validation sets (80% train, 20% val)\n",
    "train_images, val_images = train_test_split(image_files, test_size=0.2, random_state=42)\n",
    "\n",
    "# Write the relative paths of labeled images to train.txt\n",
    "with open(train_file_path, 'w') as f:\n",
    "    for image_path in train_images:\n",
    "        f.write(f\"{image_path}\\n\")\n",
    "print(f\"Found {len(image_files)} labeled images.\")\n",
    "print(f\"Created '{train_file_path}' with {len(train_images)} images for training.\")\n",
    "\n",
    "# Write the relative paths of labeled images to val.txt\n",
    "with open(val_file_path, 'w') as f:\n",
    "    for image_path in val_images:\n",
    "        f.write(f\"{image_path}\\n\")\n",
    "print(f\"Created '{val_file_path}' with {len(val_images)} images for validation.\")\n",
    "\n",
    "\n",
    "# --- Create dataset.yaml ---\n",
    "dataset_config = {\n",
    "    'path': os.path.abspath(base_path), # Use absolute path\n",
    "    'train': 'train.txt',\n",
    "    'val': 'val.txt',\n",
    "    'names': {}\n",
    "}\n",
    "classes_path = os.path.join(os.path.dirname(labels_dir), 'classes.txt')\n",
    "with open(classes_path, 'r') as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "    dataset_config['names'] = {i: name for i, name in enumerate(classes)}\n",
    "\n",
    "with open('ena24_yolo_dataset.yaml', 'w') as f:\n",
    "    yaml.dump(dataset_config, f)\n",
    "\n",
    "print(\"\\nena24_yolo_dataset.yaml created:\")\n",
    "with open('ena24_yolo_dataset.yaml', 'r') as f:\n",
    "    print(f.read())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928ab292",
   "metadata": {},
   "source": [
    "## Custom Evaluation of Pre-trained Model\n",
    "\n",
    "Before fine-tuning, let's evaluate the performance of the original pre-trained `yolov8n.pt` model on our validation set. This will show us which of the original COCO classes the model predicts for our custom-labeled objects. We will generate a custom confusion matrix where the 'True' labels are our `ena24` classes and the 'Predicted' labels are the original COCO classes.\n",
    "\n",
    "This approach allows us to see how the general-purpose COCO model interprets our specific dataset without any modification, providing a true baseline of its out-of-the-box performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf9a91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Custom Evaluation of Pre-trained Model ---\n",
    "# 1. Load original model and get COCO class names\n",
    "print(\"Loading original yolov8n.pt model...\")\n",
    "original_model = YOLO('../yolov8n.pt')\n",
    "coco_names = original_model.names\n",
    "print(f\"Loaded model with {len(coco_names)} COCO classes.\")\n",
    "\n",
    "# 2. Get custom class names from our dataset yaml\n",
    "with open('ena24_yolo_dataset.yaml', 'r') as f:\n",
    "    dataset_yaml = yaml.safe_load(f)\n",
    "custom_names = dataset_yaml['names']\n",
    "custom_names_list = [custom_names[i] for i in sorted(custom_names.keys())]\n",
    "print(f\"Loaded {len(custom_names_list)} custom classes for ENA24 dataset.\")\n",
    "\n",
    "# Add a \"Background\" class for false positives (predictions with no matching ground truth)\n",
    "custom_names_list_with_bg = custom_names_list + ['Background']\n",
    "background_class_index = len(custom_names_list)\n",
    "\n",
    "# 3. Get validation image paths\n",
    "with open(val_file_path, 'r') as f:\n",
    "    val_images = [line.strip() for line in f.readlines()]\n",
    "print(f\"Found {len(val_images)} validation images for evaluation.\")\n",
    "\n",
    "# Function to calculate IoU (Intersection over Union)\n",
    "def calculate_iou(box1, box2):\n",
    "    # box format: [x1, y1, x2, y2]\n",
    "    x1_inter = max(box1[0], box2[0])\n",
    "    y1_inter = max(box1[1], box2[1])\n",
    "    x2_inter = min(box1[2], box2[2])\n",
    "    y2_inter = min(box1[3], box2[3])\n",
    "\n",
    "    inter_area = max(0, x2_inter - x1_inter) * max(0, y2_inter - y1_inter)\n",
    "    if inter_area == 0:\n",
    "        return 0\n",
    "\n",
    "    box1_area = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "    box2_area = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "    \n",
    "    union_area = box1_area + box2_area - inter_area\n",
    "    \n",
    "    return inter_area / union_area if union_area > 0 else 0\n",
    "\n",
    "# Store true and predicted class pairs\n",
    "true_pred_pairs = []\n",
    "iou_threshold = 0.45 # IoU threshold for a match\n",
    "\n",
    "# 4. Process each validation image\n",
    "print(f\"Processing {len(val_images)} images to create confusion matrix...\")\n",
    "for image_path_relative in tqdm.tqdm(val_images):\n",
    "    image_path = os.path.join(base_path, image_path_relative)\n",
    "    # Get ground truth labels\n",
    "    relative_image_path = os.path.relpath(image_path, images_dir)\n",
    "    label_path = os.path.join(labels_dir, os.path.splitext(relative_image_path)[0] + '.txt')\n",
    "    \n",
    "    gt_boxes = []\n",
    "    gt_classes = []\n",
    "    if os.path.exists(label_path):\n",
    "        with open(label_path, 'r') as f:\n",
    "            for line in f.readlines():\n",
    "                parts = line.strip().split()\n",
    "                class_id = int(parts[0])\n",
    "                cx, cy, w, h = map(float, parts[1:])\n",
    "                gt_classes.append(class_id)\n",
    "                x1 = cx - w / 2\n",
    "                y1 = cy - h / 2\n",
    "                x2 = cx + w / 2\n",
    "                y2 = cy + h / 2\n",
    "                gt_boxes.append([x1, y1, x2, y2])\n",
    "\n",
    "    # Run inference with the original model\n",
    "    results = original_model(image_path, verbose=False)\n",
    "    pred_boxes = results[0].boxes.xyxyn.cpu().numpy() # Normalized xyxy\n",
    "    pred_classes = results[0].boxes.cls.cpu().numpy().astype(int)\n",
    "    \n",
    "    if len(gt_boxes) == 0 and len(pred_boxes) == 0:\n",
    "        continue\n",
    "\n",
    "    gt_used = np.zeros(len(gt_boxes), dtype=bool)\n",
    "    pred_used = np.zeros(len(pred_boxes), dtype=bool)\n",
    "\n",
    "    if len(pred_boxes) > 0 and len(gt_boxes) > 0:\n",
    "        iou_matrix = np.zeros((len(gt_boxes), len(pred_boxes)))\n",
    "        for i, gt_box in enumerate(gt_boxes):\n",
    "            for j, pred_box in enumerate(pred_boxes):\n",
    "                iou_matrix[i, j] = calculate_iou(gt_box, pred_box)\n",
    "        \n",
    "        matches = []\n",
    "        for i in range(len(gt_boxes)):\n",
    "            for j in range(len(pred_boxes)):\n",
    "                if iou_matrix[i, j] > iou_threshold:\n",
    "                    matches.append((iou_matrix[i, j], i, j))\n",
    "        \n",
    "        matches.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "        for iou, gt_idx, pred_idx in matches:\n",
    "            if not gt_used[gt_idx] and not pred_used[pred_idx]:\n",
    "                true_class = gt_classes[gt_idx]\n",
    "                pred_class = pred_classes[pred_idx]\n",
    "                true_pred_pairs.append((true_class, pred_class))\n",
    "                gt_used[gt_idx] = True\n",
    "                pred_used[pred_idx] = True\n",
    "\n",
    "    # Handle unmatched predictions (False Positives)\n",
    "    for j, used in enumerate(pred_used):\n",
    "        if not used:\n",
    "            true_class = background_class_index # 'Background'\n",
    "            pred_class = pred_classes[j]\n",
    "            true_pred_pairs.append((true_class, pred_class))\n",
    "\n",
    "# 5. Build and Visualize Confusion Matrix\n",
    "print(\"Building and visualizing confusion matrix...\")\n",
    "true_axis_labels = custom_names_list_with_bg\n",
    "pred_axis_labels = [coco_names[i] for i in sorted(coco_names.keys())]\n",
    "\n",
    "true_map = {name: i for i, name in enumerate(true_axis_labels)}\n",
    "pred_map = {name: i for i, name in enumerate(pred_axis_labels)}\n",
    "\n",
    "cm = np.zeros((len(true_axis_labels), len(pred_axis_labels)), dtype=int)\n",
    "\n",
    "for true_idx, pred_idx in true_pred_pairs:\n",
    "    true_name = custom_names_list_with_bg[true_idx]\n",
    "    pred_name = coco_names.get(pred_idx, \"Unknown\")\n",
    "    if pred_name in pred_map:\n",
    "        cm[true_map[true_name], pred_map[pred_name]] += 1\n",
    "\n",
    "row_sums = cm.sum(axis=1)\n",
    "col_sums = cm.sum(axis=0)\n",
    "\n",
    "non_empty_rows = np.where(row_sums > 0)[0]\n",
    "non_empty_cols = np.where(col_sums > 0)[0]\n",
    "\n",
    "if len(non_empty_rows) > 0 and len(non_empty_cols) > 0:\n",
    "    filtered_cm = cm[non_empty_rows][:, non_empty_cols]\n",
    "    filtered_y_labels = [true_axis_labels[i] for i in non_empty_rows]\n",
    "    filtered_x_labels = [pred_axis_labels[i] for i in non_empty_cols]\n",
    "\n",
    "    cm_df = pd.DataFrame(filtered_cm, index=filtered_y_labels, columns=filtered_x_labels)\n",
    "\n",
    "    plt.figure(figsize=(max(12, len(filtered_x_labels)), max(10, len(filtered_y_labels))))\n",
    "    sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title('Pre-trained Model Custom Confusion Matrix')\n",
    "    plt.ylabel(f'True Labels (ENA24)')\n",
    "    plt.xlabel(f'Predicted Labels (COCO)')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Confusion matrix is empty after filtering. No common detections were found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c16e4b",
   "metadata": {},
   "source": [
    "## Fine-Tune YOLO Model\n",
    "\n",
    "Now we can load a pretrained YOLO model and fine-tune it on our custom dataset. We'll use the `yolov8n.pt` model.\n",
    "\n",
    "If the `ena24_yolo_dataset.yaml` was created successfully, we can proceed with training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec81d652",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Load a pretrained YOLO model\n",
    "model = YOLO('../yolov8n.pt')\n",
    "\n",
    "# Train the model\n",
    "results = model.train(data='ena24_yolo_dataset.yaml', epochs=10, imgsz=640, batch=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1822e01a",
   "metadata": {},
   "source": [
    "## Visualize Training and Validation Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbfde3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the latest training directory\n",
    "train_dir = 'runs/detect'\n",
    "latest_train_run = max(os.listdir(train_dir), key=lambda d: os.path.getmtime(os.path.join(train_dir, d)))\n",
    "results_csv_path = os.path.join(train_dir, latest_train_run, 'results.csv')\n",
    "\n",
    "print(f\"Loading training results from: {results_csv_path}\")\n",
    "results_df = pd.read_csv(results_csv_path)\n",
    "\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "plt.plot(results_df['epoch'], results_df['train/box_loss']+results_df['train/cls_loss']+results_df['train/dfl_loss'], label='Train Loss')\n",
    "plt.plot(results_df['epoch'], results_df['val/box_loss']+results_df['val/cls_loss']+results_df['val/dfl_loss'], label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss Curves')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "default_lexer": "python"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
