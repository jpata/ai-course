{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b765e3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mount the drive in colab to be able to share outputs across the notebooks\n",
    "import sys\n",
    "import os\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive/')\n",
    "\n",
    "    %mkdir -p /content/drive/MyDrive/ai-course\n",
    "    %cd /content/drive/MyDrive/ai-course\n",
    "\n",
    "    if not os.path.exists('ai-course'):\n",
    "        !git clone https://github.com/jpata/ai-course\n",
    "    \n",
    "    %cd ai-course\n",
    "    !git pull"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69941944",
   "metadata": {},
   "source": [
    "# YOLO Fine-Tuning\n",
    "\n",
    "This notebook demonstrates how to fine-tune a YOLO model on a custom dataset. The dataset was labeled automatically using the OWL2 model in the `module4_owl2_object_detection.md` notebook.\n",
    "\n",
    "First, let's install the necessary libraries.\n",
    "\n",
    "```python\n",
    "#!pip install -q ultralytics pandas pyyaml scikit-learn\n",
    "```\n",
    "\n",
    "Now, let's import the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfff8af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.environ['YOLO_VERBOSE'] = 'False'\n",
    "import yaml\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tqdm\n",
    "\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f23372",
   "metadata": {},
   "source": [
    "## Create Dataset YAML\n",
    "\n",
    "YOLO models require a `dataset.yaml` file that specifies the dataset paths and class names. We will create this file now. The labels were generated by the OWL2 notebook and are located in `data/IDLE-OO-Camera-Traps/labels/test`. The corresponding images are in `data/IDLE-OO-Camera-Traps/data/test`.\n",
    "\n",
    "**Note:** The `module4_owl2_object_detection.md` notebook generates labels for a sample of 500 images. Fine-tuning on a small dataset (like 500 images, which is still relatively small for object detection) will not produce a robust model, but it demonstrates the process. For better results, you should generate labels for a larger portion of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0054f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# --- Find all labeled images and create train.txt and val.txt ---\n",
    "base_path = os.path.abspath('../data/IDLE-OO-Camera-Traps_yolo')\n",
    "labels_dir = os.path.join(base_path, 'labels')\n",
    "images_dir = os.path.join(base_path, 'images')\n",
    "train_file_path = os.path.join(base_path, 'train.txt')\n",
    "val_file_path = os.path.join(base_path, 'val.txt')\n",
    "image_files = []\n",
    "\n",
    "# Recursively find all .txt files in the labels directory, excluding classes.txt\n",
    "label_files = [f for f in glob.glob(os.path.join(labels_dir, '**/*.txt'), recursive=True) if os.path.basename(f) != 'classes.txt']\n",
    "\n",
    "for label_file in label_files:\n",
    "    # Derive the corresponding image path, assuming .png extension\n",
    "    image_path = label_file.replace(\"/labels/\", \"/images/\").replace(\".txt\", \".png\")\n",
    "    if os.path.exists(image_path):\n",
    "        image_files.append(image_path)\n",
    "\n",
    "if not image_files:\n",
    "    raise Exception(\"No labeled images found. 'train.txt' and 'val.txt' were not created.\")\n",
    "\n",
    "# Split the data into training and validation sets (80% train, 20% val)\n",
    "train_images, val_images = train_test_split(image_files, test_size=0.2, random_state=42)\n",
    "\n",
    "# Write the relative paths of labeled images to train.txt\n",
    "with open(train_file_path, 'w') as f:\n",
    "    for image_path in train_images:\n",
    "        f.write(f\"{image_path}\\n\")\n",
    "print(f\"Found {len(image_files)} labeled images.\")\n",
    "print(f\"Created '{train_file_path}' with {len(train_images)} images for training.\")\n",
    "\n",
    "# Write the relative paths of labeled images to val.txt\n",
    "with open(val_file_path, 'w') as f:\n",
    "    for image_path in val_images:\n",
    "        f.write(f\"{image_path}\\n\")\n",
    "print(f\"Created '{val_file_path}' with {len(val_images)} images for validation.\")\n",
    "\n",
    "\n",
    "# --- Create dataset.yaml ---\n",
    "dataset_config = {\n",
    "    'path': os.path.abspath(base_path), # Use absolute path\n",
    "    'train': 'train.txt',\n",
    "    'val': 'val.txt',\n",
    "    'names': {}\n",
    "}\n",
    "classes_path = os.path.join(os.path.dirname(labels_dir), 'classes.txt')\n",
    "with open(classes_path, 'r') as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "    dataset_config['names'] = {i: name for i, name in enumerate(classes)}\n",
    "\n",
    "with open('ena24_yolo_dataset.yaml', 'w') as f:\n",
    "    yaml.dump(dataset_config, f)\n",
    "\n",
    "print(\"\\nena24_yolo_dataset.yaml created:\")\n",
    "with open('ena24_yolo_dataset.yaml', 'r') as f:\n",
    "    print(f.read())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab6378f",
   "metadata": {},
   "source": [
    "## Fine-Tune YOLO Model\n",
    "\n",
    "Now we can load a pretrained YOLO model and fine-tune it on our custom dataset. We'll use the `yolov8n.pt` model.\n",
    "\n",
    "If the `ena24_yolo_dataset.yaml` was created successfully, we can proceed with training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041c9f59",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Load a pretrained YOLO model\n",
    "model = YOLO('../yolov8n.pt')\n",
    "\n",
    "# Train the model\n",
    "results = model.train(data='ena24_yolo_dataset.yaml', epochs=100, imgsz=640, batch=8, fliplr=0.5, translate=0.1, scale=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b5d8ef",
   "metadata": {},
   "source": [
    "## Visualize Training and Validation Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3db90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the latest training directory\n",
    "train_dir = 'runs/detect'\n",
    "latest_train_run = max(os.listdir(train_dir), key=lambda d: os.path.getmtime(os.path.join(train_dir, d)))\n",
    "results_csv_path = os.path.join(train_dir, latest_train_run, 'results.csv')\n",
    "\n",
    "print(f\"Loading training results from: {results_csv_path}\")\n",
    "results_df = pd.read_csv(results_csv_path)\n",
    "\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "plt.plot(results_df['epoch'], results_df['train/box_loss']+results_df['train/cls_loss']+results_df['train/dfl_loss'], label='Train Loss')\n",
    "plt.plot(results_df['epoch'], results_df['val/box_loss']+results_df['val/cls_loss']+results_df['val/dfl_loss'], label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss Curves')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "default_lexer": "python"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
